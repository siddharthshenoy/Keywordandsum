{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'./Animal Rescue incidents attended by LFB from Jan 2009.csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asar = \"./Animal Rescue incidents attended by LFB from Jan 2009.csv\"\n",
    "asar.encode('utf-8').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = pd.read_csv(asar, encoding= 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Animal assistance involving livestock - Other action'\n",
      " 'Animal rescue from below ground - Domestic pet'\n",
      " 'Animal rescue from water - Farm animal'\n",
      " 'Animal rescue from water - Domestic pet'\n",
      " 'Wild animal rescue from height'\n",
      " 'Animal rescue from height - Domestic pet'\n",
      " 'Animal rescue from water - Bird' 'Animal rescue from height - Bird'\n",
      " 'Wild animal rescue from water or mud'\n",
      " 'Animal assistance - Lift heavy livestock animal'\n",
      " 'Wild animal rescue from below ground'\n",
      " 'Animal rescue from below ground - Bird'\n",
      " 'Animal rescue from height - Farm animal'\n",
      " 'Animal rescue from below ground - Farm animal'\n",
      " 'Assist trapped domestic animal' 'Animal harm involving domestic animal'\n",
      " 'Animal assistance involving wild animal - Other action'\n",
      " 'Animal assistance involving domestic animal - Other action'\n",
      " 'Animal harm involving wild animal' 'Assist  trapped livestock animal'\n",
      " 'Assist trapped wild animal' 'Animal assistance - Lift heavy wild animal'\n",
      " 'Animal assistance - Lift heavy domestic animal'\n",
      " 'Animal harm involving livestock']\n"
     ]
    }
   ],
   "source": [
    "print(record.SpecialServiceType.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\siddharth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "seed = 69 # set random seed for whole document\n",
    "\n",
    "# Graph plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Displaying dataframes\n",
    "from IPython.display import display\n",
    "\n",
    "# Natural Language Processing Thingamajibs\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec, word2vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "import gensim\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "# Metrics to score classifiers\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, auc, roc_curve, log_loss\n",
    "\n",
    "# Data splitting, CV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n",
    "\n",
    "# Lifesaver\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "asar = \"./Animal Rescue incidents attended by LFB from Jan 2009.csv\"\n",
    "df = pd.read_csv(asar, encoding= 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'IncidentNumber':'S_NO',\n",
    "                  'DateTimeOfCall':'DATE_TIME',\n",
    "                   'CalYear':'YEAR',\n",
    "                   'FinYear':'FYEAR',\n",
    "                   'TypeOfIncident':'TYPE',\n",
    "                   'PumpCount':'PUMP_COUNT',\n",
    "                   'PumpHoursTotal':'PUMP_TOTAL',\n",
    "                   'HourlyNotionalCost(｣)':'HOUR_COST',\n",
    "                   'IncidentNotionalCost(｣)':'INCI_COST',\n",
    "                   'FinalDescription':'MAIN_DESCRIPTION',\n",
    "                   'AnimalGroupParent':'ANIMAL_TYPE',\n",
    "                   'OriginofCall':'ORIGIN',\n",
    "                   'PropertyType':'PROPERTY',\n",
    "                   'PropertyCategory':'PROPERTYCATEGORY',\n",
    "                   'SpecialServiceTypeCategory':'SERVICE_CATEGORY',\n",
    "                   'SpecialServiceType':'SERVICE_TYPE',\n",
    "                   'WardCode':'WARD_CODE',\n",
    "                   'Ward':'WARD',\n",
    "                   'BoroughCode':'BOROUGHCODE',\n",
    "                   'Borough':'BOROUGH',\n",
    "                   'StnGroundName':'GROUND_NAME',\n",
    "                   'UPRN':'UPRN',\n",
    "                   'Street':'Street',\n",
    "                   'USRN':'USRN',\n",
    "                   'PostcodeDistrict':'POST_CODE',\n",
    "                   'Easting_m':'EASTING',\n",
    "                   'Northing_m':'NORTHING',\n",
    "                   'Easting_rounded':'EASTING_R',\n",
    "                   'Northing_rounded':'NORTHING_R',\n",
    "                   'Latitude':'LAT',\n",
    "                   'Longitude':'LONGI'\n",
    "                   \n",
    "                  },inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since we wanna do complaint classification we just do the row with complaints/description in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, subset=['MAIN_DESCRIPTION'], \n",
    "          inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up dataframe for multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting dataframe into columns useful for our text multi-classification problem\n",
    "df_product_and_complaint = df[['SERVICE_TYPE', 'MAIN_DESCRIPTION']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pickling our subsetted dataframe\n",
    "#with open('df_product_and_complaint.pickle', 'wb') as to_write:\n",
    "#   pickle.dump(df_product_and_complaint, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading our pickled subsetted dataframe\n",
    "with open('df_product_and_complaint.pickle', 'rb') as to_read:\n",
    "    df_product_and_complaint = pickle.load(to_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7307 entries, 0 to 7311\n",
      "Data columns (total 3 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   SERVICE_TYPE      7307 non-null   object\n",
      " 1   MAIN_DESCRIPTION  7307 non-null   object\n",
      " 2   S_ID              7307 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 228.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_product_and_complaint.info()\n",
    "#no null values nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERVICE_TYPE</th>\n",
       "      <th>MAIN_DESCRIPTION</th>\n",
       "      <th>S_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal assistance involving livestock - Other ...</td>\n",
       "      <td>DOG WITH JAW TRAPPED IN MAGAZINE RACK,B15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal assistance involving livestock - Other ...</td>\n",
       "      <td>ASSIST RSPCA WITH FOX TRAPPED,B15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal rescue from below ground - Domestic pet</td>\n",
       "      <td>DOG CAUGHT IN DRAIN,B15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal rescue from water - Farm animal</td>\n",
       "      <td>HORSE TRAPPED IN LAKE,J17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal assistance involving livestock - Other ...</td>\n",
       "      <td>RABBIT TRAPPED UNDER SOFA,B15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        SERVICE_TYPE  \\\n",
       "0  Animal assistance involving livestock - Other ...   \n",
       "1  Animal assistance involving livestock - Other ...   \n",
       "2     Animal rescue from below ground - Domestic pet   \n",
       "3             Animal rescue from water - Farm animal   \n",
       "4  Animal assistance involving livestock - Other ...   \n",
       "\n",
       "                            MAIN_DESCRIPTION  S_ID  \n",
       "0  DOG WITH JAW TRAPPED IN MAGAZINE RACK,B15     0  \n",
       "1          ASSIST RSPCA WITH FOX TRAPPED,B15     0  \n",
       "2                    DOG CAUGHT IN DRAIN,B15     1  \n",
       "3                  HORSE TRAPPED IN LAKE,J17     2  \n",
       "4              RABBIT TRAPPED UNDER SOFA,B15     0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_product_and_complaint.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Animal rescue from height - Domestic pet                      1645\n",
       "Assist trapped domestic animal                                1503\n",
       "Animal rescue from height - Bird                               901\n",
       "Animal assistance involving livestock - Other action           633\n",
       "Assist trapped wild animal                                     593\n",
       "Animal rescue from below ground - Domestic pet                 592\n",
       "Animal assistance involving domestic animal - Other action     416\n",
       "Animal rescue from water - Domestic pet                        234\n",
       "Animal assistance involving wild animal - Other action         136\n",
       "Wild animal rescue from height                                  86\n",
       "Animal harm involving domestic animal                           80\n",
       "Wild animal rescue from below ground                            73\n",
       "Animal rescue from below ground - Bird                          68\n",
       "Animal assistance - Lift heavy livestock animal                 62\n",
       "Animal rescue from water - Farm animal                          61\n",
       "Animal rescue from water - Bird                                 53\n",
       "Assist  trapped livestock animal                                51\n",
       "Wild animal rescue from water or mud                            41\n",
       "Animal harm involving wild animal                               34\n",
       "Animal assistance - Lift heavy domestic animal                  22\n",
       "Animal rescue from below ground - Farm animal                   13\n",
       "Animal assistance - Lift heavy wild animal                       4\n",
       "Animal harm involving livestock                                  3\n",
       "Animal rescue from height - Farm animal                          3\n",
       "Name: SERVICE_TYPE, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_product_and_complaint.SERVICE_TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying encoding to the PRODUCT column\n",
    "df_product_and_complaint['S_ID'] = df_product_and_complaint['SERVICE_TYPE'].factorize()[0]\n",
    "#factorize[0] arranges the index of each encoded number accordingly to the \n",
    "# index of your categorical variables in the service_type column\n",
    "\n",
    "# Creates a dataframe of the PRODUCT to their respective PRODUCT_ID\n",
    "category_id_df = df_product_and_complaint[['SERVICE_TYPE', 'S_ID']].drop_duplicates()\n",
    "\n",
    "# Dictionaries for future use. Creating our cheatsheets for what each encoded label represents.\n",
    "category_to_id = dict(category_id_df.values) # Creates a service_type: S_ID key-value pair\n",
    "id_to_category = dict(category_id_df[['S_ID', 'SERVICE_TYPE']].values)  # Creates a S_ID: SERVICE_TYPE key-value pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERVICE_TYPE</th>\n",
       "      <th>MAIN_DESCRIPTION</th>\n",
       "      <th>S_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal assistance involving livestock - Other ...</td>\n",
       "      <td>DOG WITH JAW TRAPPED IN MAGAZINE RACK,B15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal assistance involving livestock - Other ...</td>\n",
       "      <td>ASSIST RSPCA WITH FOX TRAPPED,B15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal rescue from below ground - Domestic pet</td>\n",
       "      <td>DOG CAUGHT IN DRAIN,B15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal rescue from water - Farm animal</td>\n",
       "      <td>HORSE TRAPPED IN LAKE,J17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal assistance involving livestock - Other ...</td>\n",
       "      <td>RABBIT TRAPPED UNDER SOFA,B15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal assistance involving livestock - Other ...</td>\n",
       "      <td>ANIMAL TRAPPED BEHIND FIREPLACE,B15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal assistance involving livestock - Other ...</td>\n",
       "      <td>DOG WITH HEAD TRAPPED IN RAILINGS,B15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal rescue from water - Domestic pet</td>\n",
       "      <td>LABRADOR FALLEN THROUGH THE ICE,J15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wild animal rescue from height</td>\n",
       "      <td>SQUIRREL TRAPPED ON WINDOWSILL,B15</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal rescue from water - Domestic pet</td>\n",
       "      <td>DOG STUCK IN MUD, J15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        SERVICE_TYPE  \\\n",
       "0  Animal assistance involving livestock - Other ...   \n",
       "1  Animal assistance involving livestock - Other ...   \n",
       "2     Animal rescue from below ground - Domestic pet   \n",
       "3             Animal rescue from water - Farm animal   \n",
       "4  Animal assistance involving livestock - Other ...   \n",
       "5  Animal assistance involving livestock - Other ...   \n",
       "6  Animal assistance involving livestock - Other ...   \n",
       "7            Animal rescue from water - Domestic pet   \n",
       "8                     Wild animal rescue from height   \n",
       "9            Animal rescue from water - Domestic pet   \n",
       "\n",
       "                            MAIN_DESCRIPTION  S_ID  \n",
       "0  DOG WITH JAW TRAPPED IN MAGAZINE RACK,B15     0  \n",
       "1          ASSIST RSPCA WITH FOX TRAPPED,B15     0  \n",
       "2                    DOG CAUGHT IN DRAIN,B15     1  \n",
       "3                  HORSE TRAPPED IN LAKE,J17     2  \n",
       "4              RABBIT TRAPPED UNDER SOFA,B15     0  \n",
       "5        ANIMAL TRAPPED BEHIND FIREPLACE,B15     0  \n",
       "6      DOG WITH HEAD TRAPPED IN RAILINGS,B15     0  \n",
       "7        LABRADOR FALLEN THROUGH THE ICE,J15     3  \n",
       "8         SQUIRREL TRAPPED ON WINDOWSILL,B15     4  \n",
       "9                      DOG STUCK IN MUD, J15     3  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_product_and_complaint.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that we have encoded our columns, time to move on to the next step -- cleaning the fricken text data\n",
    "#But save our dataframe here so we don't run into memory issues later and we can start from a new starting point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pickling reduced dataframe\n",
    "#with open('df_product_and_complaint.pickle', 'wb') as to_write:\n",
    "#    pickle.dump(df_product_and_complaint, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Pickled DataFrame\n",
    "with open('df_product_and_complaint.pickle', 'rb') as to_read:\n",
    "    df_product_and_complaint = pickle.load(to_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7307 entries, 0 to 7311\n",
      "Data columns (total 3 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   SERVICE_TYPE      7307 non-null   object\n",
      " 1   MAIN_DESCRIPTION  7307 non-null   object\n",
      " 2   S_ID              7307 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 228.3+ KB\n",
      "None\n",
      "--------------------------------------------------------------------------------------\n",
      "                                           SERVICE_TYPE                           MAIN_DESCRIPTION  S_ID\n",
      "0  Animal assistance involving livestock - Other action  DOG WITH JAW TRAPPED IN MAGAZINE RACK,B15     0\n",
      "1  Animal assistance involving livestock - Other action          ASSIST RSPCA WITH FOX TRAPPED,B15     0\n",
      "2        Animal rescue from below ground - Domestic pet                    DOG CAUGHT IN DRAIN,B15     1\n",
      "3                Animal rescue from water - Farm animal                  HORSE TRAPPED IN LAKE,J17     2\n",
      "4  Animal assistance involving livestock - Other action              RABBIT TRAPPED UNDER SOFA,B15     0\n"
     ]
    }
   ],
   "source": [
    "# Reviewing our Loaded Dataframe\n",
    "print(df_product_and_complaint.info())\n",
    "print('--------------------------------------------------------------------------------------')\n",
    "print(df_product_and_complaint.head().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RABBIT TRAPPED UNDER SOFA,B15']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at a sample text\n",
    "sample_complaint = list(df_product_and_complaint.MAIN_DESCRIPTION[:5])[4]\n",
    "\n",
    "# Converting to a list for TfidfVectorizer to use\n",
    "list_sample_complaint = []\n",
    "list_sample_complaint.append(sample_complaint)\n",
    "list_sample_complaint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b15', 'rabbit', 'sofa', 'trapped']\n"
     ]
    }
   ],
   "source": [
    "# Observing what words are extracted from a TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf_idf3 = TfidfVectorizer(stop_words='english')\n",
    "check3 = tf_idf3.fit_transform(list_sample_complaint)\n",
    "\n",
    "print(tf_idf3.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model/classifier selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train/startified/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (7307,) y shape: (7307,)\n"
     ]
    }
   ],
   "source": [
    " # Split the data into X and y data sets\n",
    "X, y = df_product_and_complaint.MAIN_DESCRIPTION, df_product_and_complaint.SERVICE_TYPE\n",
    "print('X shape:', X.shape, 'y shape:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (7307,) y shape: (7307,)\n",
      "X_train (5845,)\n",
      "y_train (5845,)\n",
      "X_test (1462,)\n",
      "y_test (1462,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into X and y data sets\n",
    "X, y = df_product_and_complaint.MAIN_DESCRIPTION, df_product_and_complaint.SERVICE_TYPE\n",
    "print('X shape:', X.shape, 'y shape:', y.shape)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, \n",
    "                                                            test_size=0.2,   # 80% train/cv, 20% test\n",
    "                                                            stratify=y,\n",
    "                                                            random_state=seed)\n",
    "print('X_train', X_train_val.shape)\n",
    "print('y_train', y_train_val.shape)\n",
    "print('X_test', X_test.shape)\n",
    "print('y_test', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Text Pre-Processing\n",
    "\n",
    "# Import tfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Text Preprocessing\n",
    "# The text needs to be transformed to vectors so as the algorithms will be able make predictions. \n",
    "# In this case it will be used the Term Frequency – Inverse Document Frequency (TFIDF) weight \n",
    "# to evaluate how important A WORD is to A DOCUMENT in a COLLECTION OF DOCUMENTS.\n",
    "\n",
    "# tfidf1 = 1-gram only. \n",
    "tfidf1 = TfidfVectorizer(sublinear_tf=True, # set to true to scale the term frequency in logarithmic scale.\n",
    "                        min_df=5,\n",
    "                        stop_words='english')\n",
    "\n",
    "X_train_val_tfidf1 = tfidf1.fit_transform(X_train_val).toarray()\n",
    "X_test_tfidf1 = tfidf1.transform(X_test)\n",
    "\n",
    "# tfidf2 = unigram and bigram\n",
    "tfidf2 = TfidfVectorizer(sublinear_tf=True, # set to true to scale the term frequency in logarithmic scale.\n",
    "                        min_df=5, \n",
    "                        ngram_range=(1,2), # we consider unigrams and bigrams\n",
    "                        stop_words='english')\n",
    "X_train_val_tfidf2 = tfidf2.fit_transform(X_train_val).toarray()\n",
    "X_test_tfidf2 = tfidf2.transform(X_test)\n",
    "\n",
    "\n",
    "# # StratifiedKFold -> Split 5\n",
    "# ## We now want to do stratified kfold to preserve the proportion of the category imbalances \n",
    "# # (number is split evenly from all the classes)\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model - Train/Stratified CV with MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram number of (rows, features): (5845, 428)\n"
     ]
    }
   ],
   "source": [
    "print('1-gram number of (rows, features):', X_train_val_tfidf1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_cv_stratified(model, X_train_val, y_train_val, n_splits, name):\n",
    "    \"\"\"\n",
    "    Accepts a Model Object, converted X_train_val and y_train_val, n_splits, name\n",
    "    and returns a dataframe with various cross-validated metric scores \n",
    "    over a stratified n_splits kfold for a multi-class classifier.\n",
    "    \"\"\"\n",
    "    # Start timer\n",
    "    import timeit\n",
    "    start = timeit.default_timer()\n",
    "    \n",
    "    ### Computations below\n",
    "    \n",
    "    # StratifiedKFold\n",
    "    ## We now want to do stratified kfold to preserve the proportion of the category imbalances \n",
    "    # (number is split evenly from all the classes)\n",
    "    from sklearn.model_selection import StratifiedKFold  # incase user forgest to import\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    \n",
    "    # Initializing Metrics\n",
    "    accuracy = 0.0\n",
    "    micro_f1 = 0.0\n",
    "    macro_precision = 0.0\n",
    "    macro_recall = 0.0\n",
    "    macro_f1 = 0.0\n",
    "    weighted_precision = 0.0\n",
    "    weighted_recall = 0.0\n",
    "    weighted_f1 = 0.0\n",
    "    roc_auc = 0.0    #Not considering this score in this case\n",
    "        \n",
    "    # Storing metrics\n",
    "    from sklearn.model_selection import cross_val_score  # incase user forgets to import\n",
    "    accuracy = np.mean(cross_val_score(model, X_train_val, y_train_val, cv=kf, scoring='accuracy'))\n",
    "    micro_f1 = np.mean(cross_val_score(model, X_train_val, y_train_val, cv=kf, scoring='f1_micro'))\n",
    "    macro_precision = np.mean(cross_val_score(model, X_train_val, y_train_val, cv=kf, scoring='precision_macro'))\n",
    "    macro_recall = np.mean(cross_val_score(model, X_train_val, y_train_val, cv=kf, scoring='recall_macro'))\n",
    "    macro_f1 = np.mean(cross_val_score(model, X_train_val, y_train_val, cv=kf, scoring='f1_macro'))\n",
    "    weighted_precision = np.mean(cross_val_score(model, X_train_val, y_train_val, cv=kf, scoring='precision_weighted'))\n",
    "    weighted_recall = np.mean(cross_val_score(model, X_train_val, y_train_val, cv=kf, scoring='recall_weighted'))\n",
    "    weighted_f1 = np.mean(cross_val_score(model, X_train_val, y_train_val, cv=kf, scoring='f1_weighted'))\n",
    "    \n",
    "    # Stop timer\n",
    "    stop = timeit.default_timer()\n",
    "    elapsed_time = stop - start\n",
    "    \n",
    "    return pd.DataFrame({'Model'    : [name],\n",
    "                         'Accuracy' : [accuracy],\n",
    "                         'Micro F1' : [micro_f1],\n",
    "                         'Macro Precision': [macro_precision],\n",
    "                         'Macro Recall'   : [macro_recall],\n",
    "                         'Macro F1score'  : [macro_f1],\n",
    "                         'Weighted Precision': [weighted_precision],\n",
    "                         'Weighted Recall'   : [weighted_recall],\n",
    "                         'Weighted F1'  : [weighted_f1],\n",
    "                         'Time taken': [elapsed_time]  # timetaken: to be used for comparison later\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Data Science Story:\n",
    "# # Testing on MultinomialNB first\n",
    "\n",
    "# # Initialize Model Object\n",
    "# mnb = MultinomialNB()\n",
    "\n",
    "# results_cv_stratified_1gram = metric_cv_stratified(mnb, X_train_val_tfidf1, y_train_val, 5, 'MultinomialNB1')\n",
    "# results_cv_stratified_2gram = metric_cv_stratified(mnb, X_train_val_tfidf2, y_train_val, 5, 'MultinomialNB2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_cv_stratified_1gram' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-b0181ff75a1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresults_cv_stratified_1gram\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'results_cv_stratified_1gram' is not defined"
     ]
    }
   ],
   "source": [
    "results_cv_stratified_1gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_cv_stratified_2gram' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-c40d799d3f99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresults_cv_stratified_2gram\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'results_cv_stratified_2gram' is not defined"
     ]
    }
   ],
   "source": [
    "results_cv_stratified_2gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Testing on all Models using 1-gram \n",
    "\n",
    "# # Initialize Model Object\n",
    "# gnb = GaussianNB()\n",
    "# mnb = MultinomialNB()\n",
    "# logit = LogisticRegression(random_state=seed)\n",
    "# randomforest = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0)\n",
    "# linearsvc = LinearSVC()\n",
    "\n",
    "# ## We do NOT want these two. They take FOREVER to train AND predict\n",
    "# # knn = KNeighborsClassifier()  \n",
    "# # decisiontree = DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "# # to concat all models\n",
    "# results_cv_straitified_1gram = pd.concat([metric_cv_stratified(mnb, X_train_val_tfidf1, y_train_val, 5, 'MultinomialNB1'),\n",
    "#                                            metric_cv_stratified(gnb, X_train_val_tfidf1, y_train_val, 5, 'GaussianNB1'),\n",
    "#                                            metric_cv_stratified(logit, X_train_val_tfidf1, y_train_val, 5, 'LogisticRegression1'),\n",
    "#                                            metric_cv_stratified(randomforest, X_train_val_tfidf1, y_train_val, 5, 'RandomForest1'),\n",
    "#                                            metric_cv_stratified(linearsvc, X_train_val_tfidf1, y_train_val, 5, 'LinearSVC1')\n",
    "#                                           ], axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro F1score</th>\n",
       "      <th>Weighted Precision</th>\n",
       "      <th>Weighted Recall</th>\n",
       "      <th>Weighted F1</th>\n",
       "      <th>Time taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MultinomialNB1</td>\n",
       "      <td>0.540120</td>\n",
       "      <td>0.540120</td>\n",
       "      <td>0.205778</td>\n",
       "      <td>0.183237</td>\n",
       "      <td>0.175208</td>\n",
       "      <td>0.458353</td>\n",
       "      <td>0.540120</td>\n",
       "      <td>0.474655</td>\n",
       "      <td>1.742476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>GaussianNB1</td>\n",
       "      <td>0.116681</td>\n",
       "      <td>0.116681</td>\n",
       "      <td>0.141528</td>\n",
       "      <td>0.158912</td>\n",
       "      <td>0.103220</td>\n",
       "      <td>0.310021</td>\n",
       "      <td>0.116681</td>\n",
       "      <td>0.135088</td>\n",
       "      <td>9.085711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression1</td>\n",
       "      <td>0.568178</td>\n",
       "      <td>0.568178</td>\n",
       "      <td>0.332463</td>\n",
       "      <td>0.243235</td>\n",
       "      <td>0.246435</td>\n",
       "      <td>0.507137</td>\n",
       "      <td>0.568178</td>\n",
       "      <td>0.512977</td>\n",
       "      <td>77.167595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForest1</td>\n",
       "      <td>0.445338</td>\n",
       "      <td>0.445338</td>\n",
       "      <td>0.121989</td>\n",
       "      <td>0.110248</td>\n",
       "      <td>0.089828</td>\n",
       "      <td>0.348790</td>\n",
       "      <td>0.445338</td>\n",
       "      <td>0.340372</td>\n",
       "      <td>21.212286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC1</td>\n",
       "      <td>0.554833</td>\n",
       "      <td>0.554833</td>\n",
       "      <td>0.318929</td>\n",
       "      <td>0.274926</td>\n",
       "      <td>0.277788</td>\n",
       "      <td>0.504100</td>\n",
       "      <td>0.554833</td>\n",
       "      <td>0.512817</td>\n",
       "      <td>7.235629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                Model  Accuracy  Micro F1  Macro Precision  \\\n",
       "0      0       MultinomialNB1  0.540120  0.540120         0.205778   \n",
       "1      0          GaussianNB1  0.116681  0.116681         0.141528   \n",
       "2      0  LogisticRegression1  0.568178  0.568178         0.332463   \n",
       "3      0        RandomForest1  0.445338  0.445338         0.121989   \n",
       "4      0           LinearSVC1  0.554833  0.554833         0.318929   \n",
       "\n",
       "   Macro Recall  Macro F1score  Weighted Precision  Weighted Recall  \\\n",
       "0      0.183237       0.175208            0.458353         0.540120   \n",
       "1      0.158912       0.103220            0.310021         0.116681   \n",
       "2      0.243235       0.246435            0.507137         0.568178   \n",
       "3      0.110248       0.089828            0.348790         0.445338   \n",
       "4      0.274926       0.277788            0.504100         0.554833   \n",
       "\n",
       "   Weighted F1  Time taken  \n",
       "0     0.474655    1.742476  \n",
       "1     0.135088    9.085711  \n",
       "2     0.512977   77.167595  \n",
       "3     0.340372   21.212286  \n",
       "4     0.512817    7.235629  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_cv_straitified_1gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('results_cv_straitified_1gram_df.pickle', 'wb') as to_write:\n",
    "#     pickle.dump(results_cv_straitified_1gram, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results_cv_straitified_1gram_df.pickle', 'rb') as to_read:\n",
    "    results_cv_straitified_1gram = pickle.load(to_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing on all Models using 2-gram \n",
    "\n",
    "# # Initialize Model Object\n",
    "# gnb = GaussianNB()\n",
    "# mnb = MultinomialNB()\n",
    "# logit = LogisticRegression(random_state=seed)\n",
    "# knn = KNeighborsClassifier()\n",
    "# decisiontree = DecisionTreeClassifier(random_state=seed)\n",
    "# randomforest = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0)\n",
    "# linearsvc = LinearSVC()\n",
    "\n",
    "# # # to concat all models\n",
    "# results_cv_straitified_2gram = pd.concat([metric_cv_stratified(mnb, X_train_val_tfidf2, y_train_val, 5, 'MultinomialNB2'),\n",
    "#                                            metric_cv_stratified(gnb, X_train_val_tfidf2, y_train_val, 5, 'GaussianNB2'),\n",
    "#                                            metric_cv_stratified(logit, X_train_val_tfidf2, y_train_val, 5, 'LogisticRegression2'),\n",
    "#                                            metric_cv_stratified(randomforest, X_train_val_tfidf2, y_train_val, 5, 'RandomForest2'),\n",
    "#                                            metric_cv_stratified(linearsvc, X_train_val_tfidf2, y_train_val, 5, 'LinearSVC2')\n",
    "#                                           ], axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro F1score</th>\n",
       "      <th>Weighted Precision</th>\n",
       "      <th>Weighted Recall</th>\n",
       "      <th>Weighted F1</th>\n",
       "      <th>Time taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MultinomialNB2</td>\n",
       "      <td>0.542173</td>\n",
       "      <td>0.542173</td>\n",
       "      <td>0.201976</td>\n",
       "      <td>0.182599</td>\n",
       "      <td>0.174268</td>\n",
       "      <td>0.459225</td>\n",
       "      <td>0.542173</td>\n",
       "      <td>0.475482</td>\n",
       "      <td>2.765015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>GaussianNB2</td>\n",
       "      <td>0.211634</td>\n",
       "      <td>0.211634</td>\n",
       "      <td>0.165988</td>\n",
       "      <td>0.194780</td>\n",
       "      <td>0.148529</td>\n",
       "      <td>0.364699</td>\n",
       "      <td>0.211634</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>19.162827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression2</td>\n",
       "      <td>0.563559</td>\n",
       "      <td>0.563559</td>\n",
       "      <td>0.324405</td>\n",
       "      <td>0.240764</td>\n",
       "      <td>0.242901</td>\n",
       "      <td>0.505363</td>\n",
       "      <td>0.563559</td>\n",
       "      <td>0.508475</td>\n",
       "      <td>135.082568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForest2</td>\n",
       "      <td>0.437126</td>\n",
       "      <td>0.437126</td>\n",
       "      <td>0.090463</td>\n",
       "      <td>0.106400</td>\n",
       "      <td>0.084076</td>\n",
       "      <td>0.307927</td>\n",
       "      <td>0.437126</td>\n",
       "      <td>0.330508</td>\n",
       "      <td>37.474269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC2</td>\n",
       "      <td>0.537896</td>\n",
       "      <td>0.537896</td>\n",
       "      <td>0.311013</td>\n",
       "      <td>0.274343</td>\n",
       "      <td>0.277298</td>\n",
       "      <td>0.489277</td>\n",
       "      <td>0.537896</td>\n",
       "      <td>0.503174</td>\n",
       "      <td>7.759248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                Model  Accuracy  Micro F1  Macro Precision  \\\n",
       "0      0       MultinomialNB2  0.542173  0.542173         0.201976   \n",
       "1      0          GaussianNB2  0.211634  0.211634         0.165988   \n",
       "2      0  LogisticRegression2  0.563559  0.563559         0.324405   \n",
       "3      0        RandomForest2  0.437126  0.437126         0.090463   \n",
       "4      0           LinearSVC2  0.537896  0.537896         0.311013   \n",
       "\n",
       "   Macro Recall  Macro F1score  Weighted Precision  Weighted Recall  \\\n",
       "0      0.182599       0.174268            0.459225         0.542173   \n",
       "1      0.194780       0.148529            0.364699         0.211634   \n",
       "2      0.240764       0.242901            0.505363         0.563559   \n",
       "3      0.106400       0.084076            0.307927         0.437126   \n",
       "4      0.274343       0.277298            0.489277         0.537896   \n",
       "\n",
       "   Weighted F1  Time taken  \n",
       "0     0.475482    2.765015  \n",
       "1     0.239130   19.162827  \n",
       "2     0.508475  135.082568  \n",
       "3     0.330508   37.474269  \n",
       "4     0.503174    7.759248  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_cv_straitified_2gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro F1score</th>\n",
       "      <th>Weighted Precision</th>\n",
       "      <th>Weighted Recall</th>\n",
       "      <th>Weighted F1</th>\n",
       "      <th>Time taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MultinomialNB1</td>\n",
       "      <td>0.540120</td>\n",
       "      <td>0.540120</td>\n",
       "      <td>0.205778</td>\n",
       "      <td>0.183237</td>\n",
       "      <td>0.175208</td>\n",
       "      <td>0.458353</td>\n",
       "      <td>0.540120</td>\n",
       "      <td>0.474655</td>\n",
       "      <td>1.742476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>GaussianNB1</td>\n",
       "      <td>0.116681</td>\n",
       "      <td>0.116681</td>\n",
       "      <td>0.141528</td>\n",
       "      <td>0.158912</td>\n",
       "      <td>0.103220</td>\n",
       "      <td>0.310021</td>\n",
       "      <td>0.116681</td>\n",
       "      <td>0.135088</td>\n",
       "      <td>9.085711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression1</td>\n",
       "      <td>0.568178</td>\n",
       "      <td>0.568178</td>\n",
       "      <td>0.332463</td>\n",
       "      <td>0.243235</td>\n",
       "      <td>0.246435</td>\n",
       "      <td>0.507137</td>\n",
       "      <td>0.568178</td>\n",
       "      <td>0.512977</td>\n",
       "      <td>77.167595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForest1</td>\n",
       "      <td>0.445338</td>\n",
       "      <td>0.445338</td>\n",
       "      <td>0.121989</td>\n",
       "      <td>0.110248</td>\n",
       "      <td>0.089828</td>\n",
       "      <td>0.348790</td>\n",
       "      <td>0.445338</td>\n",
       "      <td>0.340372</td>\n",
       "      <td>21.212286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC1</td>\n",
       "      <td>0.554833</td>\n",
       "      <td>0.554833</td>\n",
       "      <td>0.318929</td>\n",
       "      <td>0.274926</td>\n",
       "      <td>0.277788</td>\n",
       "      <td>0.504100</td>\n",
       "      <td>0.554833</td>\n",
       "      <td>0.512817</td>\n",
       "      <td>7.235629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                Model  Accuracy  Micro F1  Macro Precision  \\\n",
       "0      0       MultinomialNB1  0.540120  0.540120         0.205778   \n",
       "1      0          GaussianNB1  0.116681  0.116681         0.141528   \n",
       "2      0  LogisticRegression1  0.568178  0.568178         0.332463   \n",
       "3      0        RandomForest1  0.445338  0.445338         0.121989   \n",
       "4      0           LinearSVC1  0.554833  0.554833         0.318929   \n",
       "\n",
       "   Macro Recall  Macro F1score  Weighted Precision  Weighted Recall  \\\n",
       "0      0.183237       0.175208            0.458353         0.540120   \n",
       "1      0.158912       0.103220            0.310021         0.116681   \n",
       "2      0.243235       0.246435            0.507137         0.568178   \n",
       "3      0.110248       0.089828            0.348790         0.445338   \n",
       "4      0.274926       0.277788            0.504100         0.554833   \n",
       "\n",
       "   Weighted F1  Time taken  \n",
       "0     0.474655    1.742476  \n",
       "1     0.135088    9.085711  \n",
       "2     0.512977   77.167595  \n",
       "3     0.340372   21.212286  \n",
       "4     0.512817    7.235629  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_cv_straitified_1gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('results_cv_straitified_2gram_df.pickle', 'wb') as to_write:\n",
    "#    pickle.dump(results_cv_straitified_2gram, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results_cv_straitified_2gram_df.pickle', 'rb') as to_read:\n",
    "    results_cv_straitified_2gram = pickle.load(to_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using GloVe50d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Each complaint is mapped to a feature vector by averaging the word embeddings of all words in the review. \n",
    "#These features are then fed into the defined function above for train/cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## Using pre-trained GloVe\n",
    "# #download from https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "# glove_file = glove_dir = 'glove.6B.50d.txt'\n",
    "# w2v_output_file = 'glove.6B.50d.txt.w2v'\n",
    "\n",
    "# # The following utility converts file formats\n",
    "# gensim.scripts.glove2word2vec.glove2word2vec(glove_file, w2v_output_file)\n",
    "\n",
    "# # Now we can load it!\n",
    "# glove_model_50d = gensim.models.KeyedVectors.load_word2vec_format(w2v_output_file, binary=False)\n",
    "\n",
    "# # Pickle glove model so we don't have to do the above steps again and keep the damn glove.6b.50d in our folder\n",
    "# with open('glove_model_50d.pickle', 'wb') as to_write:\n",
    "#     pickle.dump(glove_model_50d, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickled glove_model\n",
    "with open('glove_model_50d.pickle', 'rb') as to_read:\n",
    "    glove_model_50d = pickle.load(to_read)\n",
    "    \n",
    "num_features = 50 # depends on the pre-trained model you are loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complaint_to_wordlist(review, remove_stopwords=False):\n",
    "    \"\"\"\n",
    "    Convert a complaint to a list of words. Removal of stop words is optional.\n",
    "    \"\"\"\n",
    "    # remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review)\n",
    "    \n",
    "    # convert to lower case and split at whitespace\n",
    "    words = review_text.lower().split()\n",
    "    \n",
    "    # remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "\n",
    "    return words    # list of tokenized and cleaned words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_features refer to the dimensionality of the model you are using\n",
    "# model refers to the trained word2vec/glove model\n",
    "# words refer to the words in a single document/entry\n",
    "\n",
    "def make_feature_vec(words, model, num_features):\n",
    "    \"\"\"\n",
    "    Average the word vectors for a set of words\n",
    "    \"\"\"\n",
    "    feature_vec = np.zeros((num_features,),  # creates a zero matrix of (num_features, )\n",
    "                           dtype=\"float32\")  # pre-initialize (for speed)\n",
    "    \n",
    "    # Initialize a counter for the number of words in a complaint\n",
    "    nwords = 0.\n",
    "    index2word_set = set(model.index2word)  # words known to the model\n",
    "\n",
    "    \n",
    "    # Loop over each word in the comment and, if it is in the model's vocabulary, add its feature vector to the total\n",
    "    for word in words:   # for each word in the list of words\n",
    "        if word in index2word_set:   # if each word is found in the words known to the model\n",
    "            nwords = nwords + 1.     # add 1 to nwords\n",
    "            feature_vec = np.add(feature_vec, model[word])   \n",
    "    \n",
    "    # Divide by the number of words to get the average \n",
    "    if nwords > 0:\n",
    "        feature_vec = np.divide(feature_vec, nwords)\n",
    "    \n",
    "    return feature_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complaints refers to the whole corpus you intend to put in. \n",
    "# Therefore you need to append all these info from your df into a list first\n",
    "\n",
    "def get_avg_feature_vecs(complaints, model, num_features):\n",
    "    \"\"\"\n",
    "    Calculate average feature vectors for ALL complaints\n",
    "    \"\"\"\n",
    "    # Initialize a counter for indexing \n",
    "    counter = 0\n",
    "    \n",
    "    # pre-initialize (for speed)\n",
    "    complaint_feature_vecs = np.zeros((len(complaints),num_features), dtype='float32')  \n",
    "    \n",
    "    for complaint in complaints: # each complaint is made up of tokenized/cleaned/stopwords removed words\n",
    "        complaint_feature_vecs[counter] = make_feature_vec(complaint, model, num_features)\n",
    "        counter = counter + 1\n",
    "    return complaint_feature_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tokenizing and vectorizing our Train_Val Complaints (80%)\n",
    "# clean_train_val_complaints = []\n",
    "# for complaint in X_train_val:\n",
    "#     clean_train_val_complaints.append(complaint_to_wordlist(complaint, True))\n",
    "\n",
    "# X_train_val_glove_features = get_avg_feature_vecs(clean_train_val_complaints, glove_model_50d, num_features)\n",
    "\n",
    "# # Tokenizing and vectorizing our Test Complaints (20%)\n",
    "# clean_test_complaints = []\n",
    "# for complaint in X_train_val:\n",
    "#     clean_test_complaints.append(complaint_to_wordlist(complaint, True))\n",
    "\n",
    "# X_test_glove_features = get_avg_feature_vecs(clean_test_complaints, glove_model_50d, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Run the X_train_val_word2vec_features into our defined function for scoring \n",
    "\n",
    "# # Initialize Model Object\n",
    "# gnb = GaussianNB()\n",
    "# mnb = MultinomialNB()\n",
    "# logit = LogisticRegression(random_state=seed)\n",
    "# randomforest = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0)\n",
    "# linearsvc = LinearSVC()\n",
    "\n",
    "\n",
    "# # to concat all models\n",
    "# results_cv_straitified_glove50d = pd.concat([\n",
    "# #     metric_cv_stratified(mnb, X_train_val_glove_features, y_train_val, 5, 'MultinomialNB_glove50d'),\n",
    "#      metric_cv_stratified(gnb, X_train_val_glove_features, y_train_val, 5, 'GaussianNB_glove50d'),\n",
    "#      metric_cv_stratified(logit, X_train_val_glove_features, y_train_val, 5, 'LogisticRegression_glove50d'),\n",
    "#      metric_cv_stratified(randomforest, X_train_val_glove_features, y_train_val, 5, 'RandomForest_glove50d'),\n",
    "#      metric_cv_stratified(linearsvc, X_train_val_glove_features, y_train_val, 5, 'LinearSVC_glove50d')\n",
    "#     ], axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saving Results into a DF\n",
    "# with open('results_cv_straitified_glove50d.pickle', 'wb') as to_write:\n",
    "#     pickle.dump(results_cv_straitified_glove50d, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening Results\n",
    "with open('results_cv_straitified_glove50d.pickle', 'rb') as to_read:\n",
    "    results_cv_straitified_glove50d = pickle.load(to_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro F1score</th>\n",
       "      <th>Weighted Precision</th>\n",
       "      <th>Weighted Recall</th>\n",
       "      <th>Weighted F1</th>\n",
       "      <th>Time taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GaussianNB_glove50d</td>\n",
       "      <td>0.392814</td>\n",
       "      <td>0.392814</td>\n",
       "      <td>0.203111</td>\n",
       "      <td>0.244746</td>\n",
       "      <td>0.210257</td>\n",
       "      <td>0.397782</td>\n",
       "      <td>0.392814</td>\n",
       "      <td>0.388281</td>\n",
       "      <td>1.059376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression_glove50d</td>\n",
       "      <td>0.501454</td>\n",
       "      <td>0.501454</td>\n",
       "      <td>0.280851</td>\n",
       "      <td>0.209960</td>\n",
       "      <td>0.215189</td>\n",
       "      <td>0.459384</td>\n",
       "      <td>0.501454</td>\n",
       "      <td>0.451284</td>\n",
       "      <td>26.226303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForest_glove50d</td>\n",
       "      <td>0.432164</td>\n",
       "      <td>0.432164</td>\n",
       "      <td>0.119473</td>\n",
       "      <td>0.120087</td>\n",
       "      <td>0.107409</td>\n",
       "      <td>0.317063</td>\n",
       "      <td>0.432164</td>\n",
       "      <td>0.342962</td>\n",
       "      <td>55.327241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC_glove50d</td>\n",
       "      <td>0.495808</td>\n",
       "      <td>0.495808</td>\n",
       "      <td>0.235459</td>\n",
       "      <td>0.193159</td>\n",
       "      <td>0.192205</td>\n",
       "      <td>0.429242</td>\n",
       "      <td>0.495808</td>\n",
       "      <td>0.432596</td>\n",
       "      <td>147.024114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                        Model  Accuracy  Micro F1  Macro Precision  \\\n",
       "0      0          GaussianNB_glove50d  0.392814  0.392814         0.203111   \n",
       "1      0  LogisticRegression_glove50d  0.501454  0.501454         0.280851   \n",
       "2      0        RandomForest_glove50d  0.432164  0.432164         0.119473   \n",
       "3      0           LinearSVC_glove50d  0.495808  0.495808         0.235459   \n",
       "\n",
       "   Macro Recall  Macro F1score  Weighted Precision  Weighted Recall  \\\n",
       "0      0.244746       0.210257            0.397782         0.392814   \n",
       "1      0.209960       0.215189            0.459384         0.501454   \n",
       "2      0.120087       0.107409            0.317063         0.432164   \n",
       "3      0.193159       0.192205            0.429242         0.495808   \n",
       "\n",
       "   Weighted F1  Time taken  \n",
       "0     0.388281    1.059376  \n",
       "1     0.451284   26.226303  \n",
       "2     0.342962   55.327241  \n",
       "3     0.432596  147.024114  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_cv_straitified_glove50d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using GloVe100d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "del glove_model_50d, results_cv_straitified_glove50d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Using pre-trained GloVe\n",
    "# # download from https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "# num_features = 100 # depends on the pre-trained model you are loading\n",
    "\n",
    "# glove_file = glove_dir = 'glove.6B.' + str(num_features) + 'd.txt'\n",
    "# w2v_output_file = 'glove.6B.' + str(num_features) + 'd.txt.w2v'\n",
    "\n",
    "# # The following utility converts file formats\n",
    "# gensim.scripts.glove2word2vec.glove2word2vec(glove_file, w2v_output_file)\n",
    "\n",
    "# # Now we can load it!\n",
    "# glove_model_100d = gensim.models.KeyedVectors.load_word2vec_format(w2v_output_file, binary=False)\n",
    "\n",
    "# # Pickle glove model so we don't have to do the above steps again and keep the damn glove.6b.50d in our folder\n",
    "# with open('glove_model_' + str(num_features) + 'd.pickle', 'wb') as to_write:\n",
    "#     pickle.dump(glove_model_100d, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickled glove_model\n",
    "with open('glove_model_100d.pickle', 'rb') as to_read:\n",
    "    glove_model_100d = pickle.load(to_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For Train_Val Complaints (80%)\n",
    "# clean_train_val_complaints = []\n",
    "# for complaint in X_train_val:\n",
    "#     clean_train_val_complaints.append(complaint_to_wordlist(complaint, True))\n",
    "\n",
    "# X_train_val_glove_features = get_avg_feature_vecs(clean_train_val_complaints, glove_model_100d, num_features)\n",
    "\n",
    "# # For Test Complaints (20%)\n",
    "# clean_test_complaints = []\n",
    "# for complaint in X_train_val:\n",
    "#     clean_test_complaints.append(complaint_to_wordlist(complaint, True))\n",
    "\n",
    "# X_test_glove_features = get_avg_feature_vecs(clean_test_complaints, glove_model_100d, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Run the X_train_val_word2vec_features into our defined function for scoring \n",
    "\n",
    "# # Initialize Model Object\n",
    "# gnb = GaussianNB()\n",
    "# mnb = MultinomialNB()\n",
    "# logit = LogisticRegression(random_state=seed)\n",
    "# randomforest = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0)\n",
    "# linearsvc = LinearSVC()\n",
    "\n",
    "# ## We do NOT want these two. They take FOREVER to train AND predict\n",
    "# # knn = KNeighborsClassifier()  \n",
    "# # decisiontree = DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "# # to concat all models\n",
    "# results_cv_straitified_glove100d = pd.concat([\n",
    "# #     metric_cv_stratified(mnb, X_train_val_glove_features, y_train_val, 5, 'MultinomialNB_glove50d'),\n",
    "#      metric_cv_stratified(gnb, X_train_val_glove_features, y_train_val, 5, 'GaussianNB_glove100d'),\n",
    "#      metric_cv_stratified(logit, X_train_val_glove_features, y_train_val, 5, 'LogisticRegression_glove100d'),\n",
    "#      metric_cv_stratified(randomforest, X_train_val_glove_features, y_train_val, 5, 'RandomForest_glove100d'),\n",
    "#      metric_cv_stratified(linearsvc, X_train_val_glove_features, y_train_val, 5, 'LinearSVC_glove100d')\n",
    "#     ], axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('results_cv_straitified_glove100d.pickle', 'wb') as to_write:\n",
    "#     pickle.dump(results_cv_straitified_glove100d, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening Results\n",
    "with open('results_cv_straitified_glove100d.pickle', 'rb') as to_read:\n",
    "    results_cv_straitified_glove100d = pickle.load(to_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro F1score</th>\n",
       "      <th>Weighted Precision</th>\n",
       "      <th>Weighted Recall</th>\n",
       "      <th>Weighted F1</th>\n",
       "      <th>Time taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GaussianNB_glove100d</td>\n",
       "      <td>0.407528</td>\n",
       "      <td>0.407528</td>\n",
       "      <td>0.233434</td>\n",
       "      <td>0.283323</td>\n",
       "      <td>0.234904</td>\n",
       "      <td>0.451500</td>\n",
       "      <td>0.407528</td>\n",
       "      <td>0.417535</td>\n",
       "      <td>1.431750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression_glove100d</td>\n",
       "      <td>0.550214</td>\n",
       "      <td>0.550214</td>\n",
       "      <td>0.323551</td>\n",
       "      <td>0.261588</td>\n",
       "      <td>0.268414</td>\n",
       "      <td>0.499682</td>\n",
       "      <td>0.550214</td>\n",
       "      <td>0.504889</td>\n",
       "      <td>39.701219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForest_glove100d</td>\n",
       "      <td>0.457314</td>\n",
       "      <td>0.457314</td>\n",
       "      <td>0.121513</td>\n",
       "      <td>0.130589</td>\n",
       "      <td>0.116406</td>\n",
       "      <td>0.329671</td>\n",
       "      <td>0.457314</td>\n",
       "      <td>0.365411</td>\n",
       "      <td>76.902029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC_glove100d</td>\n",
       "      <td>0.552438</td>\n",
       "      <td>0.552438</td>\n",
       "      <td>0.338310</td>\n",
       "      <td>0.267908</td>\n",
       "      <td>0.273771</td>\n",
       "      <td>0.503821</td>\n",
       "      <td>0.552438</td>\n",
       "      <td>0.504627</td>\n",
       "      <td>214.637019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                         Model  Accuracy  Micro F1  Macro Precision  \\\n",
       "0      0          GaussianNB_glove100d  0.407528  0.407528         0.233434   \n",
       "1      0  LogisticRegression_glove100d  0.550214  0.550214         0.323551   \n",
       "2      0        RandomForest_glove100d  0.457314  0.457314         0.121513   \n",
       "3      0           LinearSVC_glove100d  0.552438  0.552438         0.338310   \n",
       "\n",
       "   Macro Recall  Macro F1score  Weighted Precision  Weighted Recall  \\\n",
       "0      0.283323       0.234904            0.451500         0.407528   \n",
       "1      0.261588       0.268414            0.499682         0.550214   \n",
       "2      0.130589       0.116406            0.329671         0.457314   \n",
       "3      0.267908       0.273771            0.503821         0.552438   \n",
       "\n",
       "   Weighted F1  Time taken  \n",
       "0     0.417535    1.431750  \n",
       "1     0.504889   39.701219  \n",
       "2     0.365411   76.902029  \n",
       "3     0.504627  214.637019  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_cv_straitified_glove100d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using GloVe200d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "del glove_model_100d, results_cv_straitified_glove100d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Using pre-trained GloVe\n",
    "# # download from https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "# num_features = 200 # depends on the pre-trained model you are loading\n",
    "\n",
    "# glove_file = glove_dir = 'glove.6B.' + str(num_features) + 'd.txt'\n",
    "# w2v_output_file = 'glove.6B.' + str(num_features) + 'd.txt.w2v'\n",
    "\n",
    "# # The following utility converts file formats\n",
    "# gensim.scripts.glove2word2vec.glove2word2vec(glove_file, w2v_output_file)\n",
    "\n",
    "# # Now we can load it!\n",
    "# glove_model_200d = gensim.models.KeyedVectors.load_word2vec_format(w2v_output_file, binary=False)\n",
    "\n",
    "# # Pickle glove model so we don't have to do the above steps again and keep the damn glove.6b.50d in our folder\n",
    "# with open('glove_model_' + str(num_features) + 'd.pickle', 'wb') as to_write:\n",
    "#     pickle.dump(glove_model_200d, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('glove_model_200d.pickle', 'rb') as to_read:\n",
    "    glove_model_200d = pickle.load(to_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For Train_Val Complaints (80%)\n",
    "# clean_train_val_complaints = []\n",
    "# for complaint in X_train_val:\n",
    "#     clean_train_val_complaints.append(complaint_to_wordlist(complaint, True))\n",
    "\n",
    "# X_train_val_glove_features = get_avg_feature_vecs(clean_train_val_complaints, glove_model_200d, num_features)\n",
    "\n",
    "# #Already run above\n",
    "# #For Test Complaints (20%)\n",
    "# clean_test_complaints = []\n",
    "# for complaint in X_train_val:\n",
    "#     clean_test_complaints.append(complaint_to_wordlist(complaint, True))\n",
    "\n",
    "# X_test_glove_features = get_avg_feature_vecs(clean_test_complaints, glove_model_200d, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ## Run the X_train_val_word2vec_features into our defined function for scoring \n",
    "\n",
    "# # Initialize Model Object\n",
    "# gnb = GaussianNB()\n",
    "# mnb = MultinomialNB()\n",
    "# logit = LogisticRegression(random_state=seed)\n",
    "# randomforest = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0)\n",
    "# linearsvc = LinearSVC()\n",
    "\n",
    "# ## We do NOT want these two. They take FOREVER to train AND predict\n",
    "# # knn = KNeighborsClassifier()  \n",
    "# # decisiontree = DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "# # to concat all models\n",
    "# results_cv_straitified_glove200d = pd.concat([\n",
    "# #     metric_cv_stratified(mnb, X_train_val_glove_features, y_train_val, 5, 'MultinomialNB_glove50d'),\n",
    "#      metric_cv_stratified(gnb, X_train_val_glove_features, y_train_val, 5, 'GaussianNB_glove200d'),\n",
    "#      metric_cv_stratified(logit, X_train_val_glove_features, y_train_val, 5, 'LogisticRegression_glove200d'),\n",
    "#      metric_cv_stratified(randomforest, X_train_val_glove_features, y_train_val, 5, 'RandomForest_glove200d'),\n",
    "#      metric_cv_stratified(linearsvc, X_train_val_glove_features, y_train_val, 5, 'LinearSVC_glove200d')\n",
    "#     ], axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('results_cv_straitified_glove200d.pickle', 'wb') as to_write:\n",
    "#     pickle.dump(results_cv_straitified_glove200d, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results_cv_straitified_glove200d.pickle', 'rb') as to_read:\n",
    "    results_cv_straitified_glove200d = pickle.load(to_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro F1score</th>\n",
       "      <th>Weighted Precision</th>\n",
       "      <th>Weighted Recall</th>\n",
       "      <th>Weighted F1</th>\n",
       "      <th>Time taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GaussianNB_glove200d</td>\n",
       "      <td>0.438494</td>\n",
       "      <td>0.438494</td>\n",
       "      <td>0.269655</td>\n",
       "      <td>0.321288</td>\n",
       "      <td>0.270937</td>\n",
       "      <td>0.493144</td>\n",
       "      <td>0.438494</td>\n",
       "      <td>0.451923</td>\n",
       "      <td>4.214926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression_glove200d</td>\n",
       "      <td>0.559624</td>\n",
       "      <td>0.559624</td>\n",
       "      <td>0.349456</td>\n",
       "      <td>0.282217</td>\n",
       "      <td>0.288903</td>\n",
       "      <td>0.511302</td>\n",
       "      <td>0.559624</td>\n",
       "      <td>0.516330</td>\n",
       "      <td>57.037273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForest_glove200d</td>\n",
       "      <td>0.469119</td>\n",
       "      <td>0.469119</td>\n",
       "      <td>0.124108</td>\n",
       "      <td>0.135031</td>\n",
       "      <td>0.120671</td>\n",
       "      <td>0.339093</td>\n",
       "      <td>0.469119</td>\n",
       "      <td>0.377625</td>\n",
       "      <td>107.355937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC_glove200d</td>\n",
       "      <td>0.556373</td>\n",
       "      <td>0.556373</td>\n",
       "      <td>0.317302</td>\n",
       "      <td>0.277824</td>\n",
       "      <td>0.275487</td>\n",
       "      <td>0.510566</td>\n",
       "      <td>0.556373</td>\n",
       "      <td>0.511425</td>\n",
       "      <td>453.989843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                         Model  Accuracy  Micro F1  Macro Precision  \\\n",
       "0      0          GaussianNB_glove200d  0.438494  0.438494         0.269655   \n",
       "1      0  LogisticRegression_glove200d  0.559624  0.559624         0.349456   \n",
       "2      0        RandomForest_glove200d  0.469119  0.469119         0.124108   \n",
       "3      0           LinearSVC_glove200d  0.556373  0.556373         0.317302   \n",
       "\n",
       "   Macro Recall  Macro F1score  Weighted Precision  Weighted Recall  \\\n",
       "0      0.321288       0.270937            0.493144         0.438494   \n",
       "1      0.282217       0.288903            0.511302         0.559624   \n",
       "2      0.135031       0.120671            0.339093         0.469119   \n",
       "3      0.277824       0.275487            0.510566         0.556373   \n",
       "\n",
       "   Weighted F1  Time taken  \n",
       "0     0.451923    4.214926  \n",
       "1     0.516330   57.037273  \n",
       "2     0.377625  107.355937  \n",
       "3     0.511425  453.989843  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_cv_straitified_glove200d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using GloVe300d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "del glove_model_200d, results_cv_straitified_glove200d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Using pre-trained GloVe\n",
    "# # download from https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "# num_features = 300 # depends on the pre-trained model you are loading\n",
    "\n",
    "# glove_file = glove_dir = 'glove.6B.' + str(num_features) + 'd.txt'\n",
    "# w2v_output_file = 'glove.6B.' + str(num_features) + 'd.txt.w2v'\n",
    "\n",
    "# # The following utility converts file formats\n",
    "# gensim.scripts.glove2word2vec.glove2word2vec(glove_file, w2v_output_file)\n",
    "\n",
    "# # Now we can load it!\n",
    "# glove_model_300d = gensim.models.KeyedVectors.load_word2vec_format(w2v_output_file, binary=False)\n",
    "\n",
    "# # Pickle glove model so we don't have to do the above steps again and keep the damn glove.6b.50d in our folder\n",
    "# with open('glove_model_' + str(num_features) + 'd.pickle', 'wb') as to_write:\n",
    "#     pickle.dump(glove_model_300d, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load pickled glove_model\n",
    "# with open('glove_model_300d.pickle', 'rb') as to_read:\n",
    "#     glove_model_300d = pickle.load(to_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # For Train_Val Complaints (80%)\n",
    "# clean_train_val_complaints = []\n",
    "# for complaint in X_train_val:\n",
    "#     clean_train_val_complaints.append(complaint_to_wordlist(complaint, True))\n",
    "\n",
    "# X_train_val_glove_features = get_avg_feature_vecs(clean_train_val_complaints, glove_model_300d, num_features)\n",
    "\n",
    "# #Already run above\n",
    "# # For Test Complaints (20%)\n",
    "# clean_test_complaints = []\n",
    "# for complaint in X_train_val:\n",
    "#     clean_test_complaints.append(complaint_to_wordlist(complaint, True))\n",
    "\n",
    "# X_test_glove_features = get_avg_feature_vecs(clean_test_complaints, glove_model_300d, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Run the X_train_val_word2vec_features into our defined function for scoring \n",
    "\n",
    "# # Initialize Model Object\n",
    "# gnb = GaussianNB()\n",
    "# mnb = MultinomialNB()\n",
    "# logit = LogisticRegression(random_state=seed)\n",
    "# randomforest = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0)\n",
    "# linearsvc = LinearSVC()\n",
    "\n",
    "# ## We do NOT want these two. They take FOREVER to train AND predict\n",
    "# # knn = KNeighborsClassifier()  \n",
    "# # decisiontree = DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "# # to concat all models\n",
    "# results_cv_straitified_glove300d= pd.concat([\n",
    "#     # metric_cv_stratified(mnb, X_train_val_glove_features, y_train_val, 5, 'MultinomialNB_glove50d'),\n",
    "#      metric_cv_stratified(gnb, X_train_val_glove_features, y_train_val, 5, 'GaussianNB_glove300d'),\n",
    "#      metric_cv_stratified(logit, X_train_val_glove_features, y_train_val, 5, 'LogisticRegression_glove300d'),\n",
    "#      metric_cv_stratified(randomforest, X_train_val_glove_features, y_train_val, 5, 'RandomForest_glove300d'),\n",
    "#      metric_cv_stratified(linearsvc, X_train_val_glove_features, y_train_val, 5, 'LinearSVC_glove300d')\n",
    "#     ], axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with open('results_cv_straitified_glove300d.pickle', 'wb') as to_write:\n",
    "#     pickle.dump(results_cv_straitified_glove300d, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening Results\n",
    "with open('results_cv_straitified_glove300d.pickle', 'rb') as to_read:\n",
    "    results_cv_straitified_glove300d = pickle.load(to_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro F1score</th>\n",
       "      <th>Weighted Precision</th>\n",
       "      <th>Weighted Recall</th>\n",
       "      <th>Weighted F1</th>\n",
       "      <th>Time taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GaussianNB_glove300d</td>\n",
       "      <td>0.423952</td>\n",
       "      <td>0.423952</td>\n",
       "      <td>0.267595</td>\n",
       "      <td>0.321662</td>\n",
       "      <td>0.270538</td>\n",
       "      <td>0.483721</td>\n",
       "      <td>0.423952</td>\n",
       "      <td>0.438690</td>\n",
       "      <td>5.351046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression_glove300d</td>\n",
       "      <td>0.563216</td>\n",
       "      <td>0.563216</td>\n",
       "      <td>0.355575</td>\n",
       "      <td>0.285609</td>\n",
       "      <td>0.291020</td>\n",
       "      <td>0.515556</td>\n",
       "      <td>0.563216</td>\n",
       "      <td>0.521305</td>\n",
       "      <td>52.767000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForest_glove300d</td>\n",
       "      <td>0.482806</td>\n",
       "      <td>0.482806</td>\n",
       "      <td>0.140454</td>\n",
       "      <td>0.138775</td>\n",
       "      <td>0.124503</td>\n",
       "      <td>0.372200</td>\n",
       "      <td>0.482806</td>\n",
       "      <td>0.390671</td>\n",
       "      <td>116.899824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC_glove300d</td>\n",
       "      <td>0.555175</td>\n",
       "      <td>0.555175</td>\n",
       "      <td>0.307301</td>\n",
       "      <td>0.279014</td>\n",
       "      <td>0.279385</td>\n",
       "      <td>0.505137</td>\n",
       "      <td>0.555175</td>\n",
       "      <td>0.514641</td>\n",
       "      <td>508.521242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                         Model  Accuracy  Micro F1  Macro Precision  \\\n",
       "0      0          GaussianNB_glove300d  0.423952  0.423952         0.267595   \n",
       "1      0  LogisticRegression_glove300d  0.563216  0.563216         0.355575   \n",
       "2      0        RandomForest_glove300d  0.482806  0.482806         0.140454   \n",
       "3      0           LinearSVC_glove300d  0.555175  0.555175         0.307301   \n",
       "\n",
       "   Macro Recall  Macro F1score  Weighted Precision  Weighted Recall  \\\n",
       "0      0.321662       0.270538            0.483721         0.423952   \n",
       "1      0.285609       0.291020            0.515556         0.563216   \n",
       "2      0.138775       0.124503            0.372200         0.482806   \n",
       "3      0.279014       0.279385            0.505137         0.555175   \n",
       "\n",
       "   Weighted F1  Time taken  \n",
       "0     0.438690    5.351046  \n",
       "1     0.521305   52.767000  \n",
       "2     0.390671  116.899824  \n",
       "3     0.514641  508.521242  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_cv_straitified_glove300d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GoogleNews Word2Vec300d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glove_model_300d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-51db6c23b575>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdel\u001b[0m \u001b[0mglove_model_300d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults_cv_straitified_glove300d\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'glove_model_300d' is not defined"
     ]
    }
   ],
   "source": [
    "del glove_model_300d, results_cv_straitified_glove300d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Using pre-trained GoogleNews Word2Vec\n",
    "# # download from https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit\n",
    "\n",
    "# num_features = 300 # depends on the pre-trained model you are loading\n",
    "\n",
    "# # Path to where the word2vec file lives\n",
    "# google_vec_file = 'GoogleNews-vectors-negative300.bin'\n",
    "\n",
    "# # Load it!  This might take a few minutes...\n",
    "# word2vec_model_300d = gensim.models.KeyedVectors.load_word2vec_format(google_vec_file, binary=True)\n",
    "# # it is just loading all the different weights (embedding) into python\n",
    "\n",
    "\n",
    "# # Pickle word2vec 300d model so we don't have to do the above steps again and keep the damn file in our folder\n",
    "# with open('word2vec_model_' + str(num_features) + 'd.pickle', 'wb') as to_write:\n",
    "#     pickle.dump(word2vec_model_300d, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickled glove_model\n",
    "with open('word2vec_model_300d.pickle', 'rb') as to_read:\n",
    "    word2vec_model_300d = pickle.load(to_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For Train_Val Complaints (80%)\n",
    "# clean_train_val_complaints = []\n",
    "# for complaint in X_train_val:\n",
    "#     clean_train_val_complaints.append(complaint_to_wordlist(complaint, True))\n",
    "\n",
    "# X_train_val_glove_features = get_avg_feature_vecs(clean_train_val_complaints, word2vec_model_300d, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "D:\\anacondasetup\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# ## Run the X_train_val_word2vec_features into our defined function for scoring \n",
    "\n",
    "# # Initialize Model Object\n",
    "# gnb = GaussianNB()\n",
    "# mnb = MultinomialNB()\n",
    "# logit = LogisticRegression(random_state=seed)\n",
    "# randomforest = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0)\n",
    "# linearsvc = LinearSVC()\n",
    "\n",
    "# ## We do NOT want these two. They take FOREVER to train AND predict\n",
    "# # knn = KNeighborsClassifier()  \n",
    "# # decisiontree = DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "# # to concat all models\n",
    "# results_cv_straitified_word2vec300d= pd.concat([\n",
    "# #     metric_cv_stratified(mnb, X_train_val_glove_features, y_train_val, 5, 'MultinomialNB_glove50d'),\n",
    "#      metric_cv_stratified(gnb, X_train_val_glove_features, y_train_val, 5, 'GaussianNB_word2vec300d'),\n",
    "#      metric_cv_stratified(logit, X_train_val_glove_features, y_train_val, 5, 'LogisticRegression_word2vec300d'),\n",
    "#      metric_cv_stratified(randomforest, X_train_val_glove_features, y_train_val, 5, 'RandomForest_word2vec300d'),\n",
    "#      metric_cv_stratified(linearsvc, X_train_val_glove_features, y_train_val, 5, 'LinearSVC_word2vec300d')\n",
    "#     ], axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('results_cv_straitified_word2vec300d.pickle', 'wb') as to_write:\n",
    "#     pickle.dump(results_cv_straitified_word2vec300d, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening Results\n",
    "with open('results_cv_straitified_word2vec300d.pickle', 'rb') as to_read:\n",
    "    results_cv_straitified_word2vec300d = pickle.load(to_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro F1score</th>\n",
       "      <th>Weighted Precision</th>\n",
       "      <th>Weighted Recall</th>\n",
       "      <th>Weighted F1</th>\n",
       "      <th>Time taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GaussianNB_word2vec300d</td>\n",
       "      <td>0.443798</td>\n",
       "      <td>0.443798</td>\n",
       "      <td>0.275011</td>\n",
       "      <td>0.324800</td>\n",
       "      <td>0.278742</td>\n",
       "      <td>0.497051</td>\n",
       "      <td>0.443798</td>\n",
       "      <td>0.458056</td>\n",
       "      <td>6.846028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression_word2vec300d</td>\n",
       "      <td>0.571086</td>\n",
       "      <td>0.571086</td>\n",
       "      <td>0.340366</td>\n",
       "      <td>0.267344</td>\n",
       "      <td>0.270382</td>\n",
       "      <td>0.507931</td>\n",
       "      <td>0.571086</td>\n",
       "      <td>0.518040</td>\n",
       "      <td>60.654012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForest_word2vec300d</td>\n",
       "      <td>0.487254</td>\n",
       "      <td>0.487254</td>\n",
       "      <td>0.127341</td>\n",
       "      <td>0.139426</td>\n",
       "      <td>0.123645</td>\n",
       "      <td>0.354823</td>\n",
       "      <td>0.487254</td>\n",
       "      <td>0.392394</td>\n",
       "      <td>131.267324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC_word2vec300d</td>\n",
       "      <td>0.565098</td>\n",
       "      <td>0.565098</td>\n",
       "      <td>0.329401</td>\n",
       "      <td>0.287856</td>\n",
       "      <td>0.286680</td>\n",
       "      <td>0.508738</td>\n",
       "      <td>0.565098</td>\n",
       "      <td>0.517656</td>\n",
       "      <td>224.554236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                            Model  Accuracy  Micro F1  \\\n",
       "0      0          GaussianNB_word2vec300d  0.443798  0.443798   \n",
       "1      0  LogisticRegression_word2vec300d  0.571086  0.571086   \n",
       "2      0        RandomForest_word2vec300d  0.487254  0.487254   \n",
       "3      0           LinearSVC_word2vec300d  0.565098  0.565098   \n",
       "\n",
       "   Macro Precision  Macro Recall  Macro F1score  Weighted Precision  \\\n",
       "0         0.275011      0.324800       0.278742            0.497051   \n",
       "1         0.340366      0.267344       0.270382            0.507931   \n",
       "2         0.127341      0.139426       0.123645            0.354823   \n",
       "3         0.329401      0.287856       0.286680            0.508738   \n",
       "\n",
       "   Weighted Recall  Weighted F1  Time taken  \n",
       "0         0.443798     0.458056    6.846028  \n",
       "1         0.571086     0.518040   60.654012  \n",
       "2         0.487254     0.392394  131.267324  \n",
       "3         0.565098     0.517656  224.554236  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_cv_straitified_word2vec300d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
